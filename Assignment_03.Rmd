---
title: "Assignment_3"
author: 'Yingtong Zhang'
date: "Jan 31, 2019"
output: html_document
---

The objective of today's exercise is to provide a quick introduction to some common tools for dealing with big data. For each tool we are just using the most basic syntax and you are encouraged to go back and read the help for each at a later date. This exercise also focuses on "general purpose" tools. There are a multitude of R libraries available for accessing specific data sources and web services. A quick summary of some of these is available at http://cran.r-project.org/web/views/WebTechnologies.html. In addition, a Google search on many of the tools and topics covered in Chapters 3 and 4 will provide a lot of additional info on big data tools outside of R.

Note: The code in this exercise will download data off the web dynamically, which can take some time, so try to "knit" infrequently.

```{r,echo=FALSE}
## since libraries will be pulled, make sure repository is set
repos = "http://cran.us.r-project.org"
get.pkg <- function(pkg){
  loaded <- do.call("require",list(package=pkg))
  if(!loaded){
    print(paste("trying to install",pkg))
    install.packages(pkg,dependencies=TRUE,repos=repos)
    loaded <- do.call("require",list(package=pkg))
    if(loaded){
      print(paste(pkg,"installed and loaded"))
    } 
    else {
      stop(paste("could not install",pkg))
    }    
  }
}
get.pkg("RCurl")
get.pkg("XML")
get.pkg("ncdf4")
get.pkg("devtools")
library("MODISTools")
```

Note: The MODISTools library is no longer on CRAN, but can be downloaded manually from the ORNL DAAC here: https://modis.ornl.gov/data/modis_webservice.html



**Question 1:**

Using the US Forest Service's Forest Inventory and Analysis (FIA) data set, plot the rank vs log(abundance) curve for tree seedling counts from Rhode Island. Data is available at https://apps.fs.usda.gov/fia/datamart/CSV/RI_SEEDLING.csv and the relevant columns are TREECOUNT (raw seedling counts) and SPCD (species codes). 
Hints: tapply, sum, na.rm=TRUE, sort, decreasing=TRUE, log='y'

```{r}
data_FIA = read.csv("https://apps.fs.usda.gov/fia/datamart/CSV/RI_SEEDLING.csv")
count_by_code <- sort(tapply(data_FIA$TREECOUNT, data_FIA$SPCD, sum, na.rm = TRUE), decreasing = TRUE)

plot(1:length(count_by_code), log(count_by_code), type='l', xlab = 'Abundance Rank', ylab = 'Abundance(log)')
```



Web Scraping
------------

Often the data that we want to use from the web has been formatted in HTML for human-readability rather than in tab- or comma-delimited files for inport and export. The process of extracting data from webpages has been dubbed **scraping**. For these sorts of more complex problems we can use the RCurl library to grab HTML or XML structured content directly off the web, and then use the XML library to parse the markup into more standard R data objects. In the example below we grab data on the status of all the files that make up the FIA in order to look for files that have been updated after a certain date.

```{r}
nu <- function(x){as.numeric(as.character(x))}  ## simple function to convert data to numeric

fia_html <- getURL("https://apps.fs.usda.gov/fia/datamart/CSV/datamart_csv.html")  ## grab raw html
fia_table = readHTMLTable(fia_html)[[3]]    ## We're interested in the 3rd table on this webpage
update = as.Date(fia_table[,"Last Modified Date"])
hist(update,"months")                       ## Plot a histogram of update times
recent <- fia_table[which(update > "2016/01/01"),]
```

**Question 2:**
Create a sorted table of how many FLUXNET eddy-covariance towers are in each country according to the website at http://fluxnet.fluxdata.org/sites/site-list-and-pages/. 
Hint: use substring to extract the country code from the overall FLUXNET ID code.

```{r}
nu <- function(x){as.numeric(as.character(x))}  ## simple function to convert data to numeric

fluxnet_table = readHTMLTable("FLUXNET2015Sites.html")[[1]]   ## We're interested in the 3rd table on this webpage
#update = as.Date(fia_table[,"Last Modified Date"])
#hist(update,"months")                       ## Plot a histogram of update times
#recent <- fia_table[which(update > "2016/01/01"),]
```

















